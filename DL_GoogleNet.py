# -*- coding: utf-8 -*-
"""GoogleNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sFDWXw2yYDljVQRomYWuKCuIL3EwqMDV
"""

import time
import copy
import numpy as np
import matplotlib.pyplot as plt
import os

import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from tqdm import tqdm

from GoogleNet_Module import Inception, InceptionBlock, AuxiliaryBlock, ConvBlock

torch.manual_seed(42)

device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)

if device == "cuda":
    num_workers = 4
else:
    num_workers = 1

transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])

if __name__ == "__main__":
    # load the image folder dataset
    train_dataset = torchvision.datasets.ImageFolder(
        root=f"{os.getcwd()}/spectrograms", transform=transform
    )
    test_dataset = torchvision.datasets.ImageFolder(
        root=f"{os.getcwd()}/spectrograms_val", transform=transform
    )

    batch_size = 64
    train_loader = DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers
    )
    test_loader = DataLoader(
        test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers
    )

    # from torchvision.utils import make_grid

    # for images, _ in train_loader:
    #     plt.figure(figsize=(16,8))
    #     plt.axis('off')
    #     plt.imshow(make_grid(images, nrow=8).permute((1, 2, 0)))
    #     break

    model = Inception().to(device)
    next(model.parameters()).is_cuda

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)
    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

    def train_model(
        model, dataloaders, criterion, optimizer, num_epochs=45, use_auxiliary=True
    ):

        since = time.time()
        val_acc_history = []
        loss_history = []
        best_model_wts = copy.deepcopy(model.state_dict())
        best_acc = 0.0

        for epoch in range(num_epochs):
            print("Epoch {}/{}".format(epoch + 1, num_epochs))
            print("-" * 10)

            for phase in [
                "train",
                "val",
            ]:  # Each epoch has a training and validation phase
                if phase == "train":
                    model.train()  # Set model to training mode
                else:
                    model.eval()  # Set model to evaluate mode

                running_loss = 0.0
                running_corrects = 0

                for inputs, labels in dataloaders[phase]:  # Iterate over data

                    inputs = inputs.to(device)

                    labels = labels.to(device)

                    optimizer.zero_grad()  # Zero the parameter gradients

                    with torch.set_grad_enabled(
                        phase == "train"
                    ):  # Forward. Track history if only in train

                        if (
                            phase == "train"
                        ):  # Backward + optimize only if in training phase
                            if use_auxiliary:
                                outputs, aux1, aux2 = model(inputs)
                                loss = (
                                    criterion(outputs, labels)
                                    + 0.3 * criterion(aux1, labels)
                                    + 0.3 * criterion(aux2, labels)
                                )
                            else:
                                outputs, _, _ = model(inputs)
                                loss = criterion(outputs, labels)

                            _, preds = torch.max(outputs, 1)
                            loss.backward()
                            optimizer.step()

                        if phase == "val":
                            outputs, _, _ = model(inputs)
                            loss = criterion(outputs, labels)
                            _, preds = torch.max(outputs, 1)

                    running_loss += loss.item() * inputs.size(0)
                    running_corrects += torch.sum(preds == labels.data)

                epoch_loss = running_loss / len(dataloaders[phase].dataset)
                loss_history.append(epoch_loss)

                if phase == "val":  # Adjust learning rate based on val loss
                    lr_scheduler.step(epoch_loss)

                epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)

                print(
                    "{} Loss: {:.4f} Acc: {:.4f}".format(phase, epoch_loss, epoch_acc)
                )

                # deep copy the model
                if phase == "val" and epoch_acc > best_acc:
                    best_acc = epoch_acc
                    best_model_wts = copy.deepcopy(model.state_dict())
                    # if(epoch % 10 ==0):
                    #   torch.save(model.state_dict(),"Googlenet_params.pth")
                if phase == "val":
                    val_acc_history.append(epoch_acc)

            print()

        time_elapsed = time.time() - since
        print(
            "Training complete in {:.0f}m {:.0f}s".format(
                time_elapsed // 60, time_elapsed % 60
            )
        )
        print("Best val Acc: {:4f}".format(best_acc))

        # load best model weights
        model.load_state_dict(best_model_wts)
        return model, val_acc_history, loss_history

    model, val_acc_history, loss_history = train_model(
        model, {"train": train_loader, "val": test_loader}, criterion, optimizer
    )

    plt.figure(figsize=(16, 8))
    val_acc_history_value = [i.item() for i in val_acc_history]
    plt.plot(val_acc_history_value, label="Validation Accuracy")
    plt.legend()
    plt.savefig("val_acc_history_GN.png")

    plt.figure(figsize=(16, 8))
    plt.plot(loss_history, label="Loss")
    plt.legend()
    plt.savefig("loss_history_GN.png")

    torch.save(model.state_dict(), "Googlenet_params_final.pth")

    def calculate_metrics(model, test_loader):
        model.eval()
        y_pred = []
        y_true = []
        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs = inputs.to(device)
                labels = labels.to(device)
                outputs, _, _ = model(inputs)
                _, preds = torch.max(outputs, 1)
                y_pred.extend(preds.cpu().numpy())
                y_true.extend(labels.cpu().numpy())
        return y_true, y_pred

    y_true, y_pred = calculate_metrics(model, test_loader)

    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average="weighted")
    recall = recall_score(y_true, y_pred, average="weighted")
    f1 = f1_score(y_true, y_pred, average="weighted")

    print(f"Accuracy: {'%.4f'%accuracy}")
    print(f"Precision: {'%.4f'%precision}")
    print(f"Recall: {'%.4f'%recall}")
    print(f"F1 Score: {'%.4f'%f1}")

    from sklearn.metrics import confusion_matrix
    import seaborn as sns

    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(12, 8))
    sns.heatmap(
        cm,
        annot=True,
        cmap="Reds",
        xticklabels=train_dataset.classes,
        yticklabels=train_dataset.classes,
    )
    plt.xlabel("Predicted labels")
    plt.ylabel("True labels")
    plt.title("Confusion Matrix for GoogleNet")
    plt.show()
    plt.savefig("conf_GN.png")
